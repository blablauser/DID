require 'rubygems'
require 'net/http'
require 'nokogiri'
require_relative 'csv_processor.rb'
require_relative 'db_processor.rb'
require_relative 'castaway.rb'
#require_relative 'episode.rb'
#require_relative 'song.rb' 
#require_relative 'book.rb'
#require_relative 'luxury.rb'

# exports the lit of names out of the individual links
class Collector
  attr_accessor :base_url, :names, :wikipediaLinks, :notOnWikiNames, :error

  def initialize
    @names = []
    @songs = []
    @wikipediaLinks = []
    @notOnWikiNames = []
    @searchedNames = []
    @base_url="http://www.bbc.co.uk"
    DbProcessor.create_db
  end

  def read_page controller, url
    #get the individual links, for every guest, and the list of names
    individualLinks = []
    listOfNames = []
    page_response = Net::HTTP.get_response(URI(url)).body
    document_response = Nokogiri::HTML page_response
    individualLinks = document_response.xpath("//div[@class='text grid_28 fl_right']/h4/a/@href")
    listOfNames = document_response.xpath("//div[@class='text grid_28 fl_right']/h4/a/text()")
    for link in individualLinks
      controller.read_individual_link(@base_url+link)
    end
  end

  def read_individual_link url
    #parse every individual page
    occupations = []
    page_response = Net::HTTP.get_response(URI(url)).body
    guest_doc = Nokogiri::HTML page_response
    name = guest_doc.xpath("//div[@id='castaway_intro']/h1/text()").to_s
    wikipediaLink = guest_doc.xpath("//div[@id='castaway_links']/div/div/p/a/@href")
    wikipediaLinkDescription = guest_doc.xpath("//div[@id='castaway_links']/div/div/p/a/text()")
    occupations = guest_doc.xpath("//div[@id='castaway_occupations']/div/div/p/a/text()")

    if !@names.include? name
      @names.push(name)
      if !wikipediaLinkDescription.to_s.include? "Wikipedia"
        wikipediaLink = "NA"
        @notOnWikiNames.push(name)
      end
      @wikipediaLinks.push(wikipediaLink)
      person = Castaway.new(name, wikipediaLink, occupations, "Not av.")
      searchName = name.gsub!(" ", "_").to_s
      #search wiki name: 
      # check if it's a Dame or Sir
      if (searchName.start_with? "Dame_")
        searchName.slice! "Dame_"
        else 
        if (searchName.start_with? "Sir_")
        searchName.slice! "Sir_"
      	end
      end

      # req timeout code == 408
      puts "link: http://en.wikipedia.org/wiki/#{searchName}"
      begin
  		timeout(2) do
    	# do whatever
    	if (((response = Net::HTTP.get_response(URI("http://en.wikipedia.org/wiki/"+searchName))).code==404) or (response.body.size < 19000))
        #not on wiki
        @searchedNames.push(searchName)
      puts "body size: #{response.body.size}" # > 19000
      puts "code: #{response.code}" # != 404
      puts "guest not on wiki"
      	
      end

 		 end  
	  end
      rescue Timeout::Error
  	  puts "I hope this works... "
            
      # add to the not on wiki file


      #person added. Now add episode(s)

    end

    return
  end


  def runner controller, url
    for i in (1..145)
      controller.read_page(controller, url+i.to_s)
    end

    puts "Guests: "
    puts @names.length

    #either one works just fine
    #namesOnWiki=Hash[@names.group_by { |x| x }.map { |k, v| [k, v.count] }]
    #distinctNames = @names.inject(Hash.new(0)) {|h,x| h[x]+=1;h}.to_a
    #puts distinctNames.length
    #distinctLinks = @wikipediaLinks.inject(Hash.new(0)) {|h,x| h[x]+=1;h}.to_a
    #namesOffWiki=Hash[@names.group_by { |x| x }.map { |k, v| [k, v.count] }]

    #write to CSV:

    #CsvProcessor.addNewRowToNamesCsv(@names)

    puts "Not on wiki: "
    puts @searchedNames
    for name in @searchedNames
      guest = []
      guest.push(name)
      CsvProcessor.addNewRowToNACsv(guest)
    end
    #CsvProcessor.addNewRowToNACsv(@notOnWikiNames)


    puts "__________>>>"
  end
end


controller = Collector.new
#controller.runner(controller, "http://www.bbc.co.uk/radio4/features/desert-island-discs/find-a-castaway/a-z/d/page/")
controller.runner(controller, "http://www.bbc.co.uk/radio4/features/desert-island-discs/find-a-castaway/page/")
